experiment: # Name of the expirement 
    name: "test_1000" # This will be used to save the best model weights
    base_path: "/home/chamika2/cost_model" 

data_generation:
    train_dataset_file: "/home/chamika2/cost_model/dataset/1000_train.json"  # training / validation set
    valid_dataset_file: "/home/chamika2/cost_model/dataset/1000_valid.json"
    benchmark_dataset_file: "/path/to/the/benchmarks/dataset"
    dataset_name:  "1000_batches"
    batch_size: 2048
    nb_processes: 4 # Number of processes to use when loading the data in parallel

training: 
    log_file: "logs.txt" # Just the name
    lr: 0.001
    max_epochs: 10 
    training_gpu: "cuda:0"
    validation_gpu: "cuda:0"
    continue_training: False # Continue training from saved model checkpoint
    model_weights_path: "/home/chamika2/cost_model/weights" # Model weights to use for finetuning

testing:
    testing_model_weights_path: "/home/chamika2/cost_model/weights/best_model_test_1000_4268.pt" # Model weights to evaluate
    pred_file: "/home/chamika2/cost_model/predictions.txt"
    gpu: "cuda:0" # GPU to validate on

wandb: 
    use_wandb: False # Track model progress using the Weights & Biases platform
    project: "release_model" # Name of the project to add this expirement to
    
model: 
    input_size: 846 # Size of the input. Here we specify the size of the computation vector.
#    input_size: 1790
#    comp_embed_layer_sizes:
#        - 600
#        - 350
#        - 200
#        - 180
    comp_embed_layer_sizes:
        - 1800
        - 1050
        - 600
        - 540
    drops:
        - 0.050
        - 0.050
        - 0.050
        - 0.050
        - 0.050

defaults:
  - override hydra/job_logging: disabled